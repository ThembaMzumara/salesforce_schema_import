{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3986265c-2b1a-40f8-bdd1-d139c92f0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Cell 1: Imports and Setup\n",
    "import os\n",
    "\n",
    "# List of required packages\n",
    "required_packages = {\n",
    "    'pandas': 'pandas',\n",
    "    'matplotlib': 'matplotlib',\n",
    "    'seaborn': 'seaborn',\n",
    "    'chardet': 'chardet'\n",
    "}\n",
    "\n",
    "# Check and install missing packages\n",
    "for package, import_name in required_packages.items():\n",
    "    try:\n",
    "        __import__(import_name)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        !pip install {package}\n",
    "\n",
    "# Now import all required packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import chardet\n",
    "\n",
    "from infer_data_type import EnhancedSalesforceValidator\n",
    "\n",
    "# Display settings for better output readability\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ce156-8214-4a4d-9e4e-2ce806c2f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Cell 2: Data Loading and Preparation\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load data with proper encoding detection\"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(file_path)\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                encoding = chardet.detect(f.read(100000))['encoding']\n",
    "            return pd.read_csv(file_path, encoding=encoding)\n",
    "        except:\n",
    "            return pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Path to your CSV\n",
    "file_path = os.path.join(\"..\", \"csv_files\", \"extract.csv\")\n",
    "\n",
    "try:\n",
    "    df = load_data(file_path)\n",
    "    print(\"Dataset Overview:\")\n",
    "    print(f\"Rows: {len(df)}, Columns: {len(df.columns)}\")\n",
    "    print(\"\\nSample of data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find file at {file_path}\")\n",
    "    print(\"Please check the file path and ensure the CSV file exists.\")\n",
    "    df = None\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {str(e)}\")\n",
    "    print(\"Please check the file path and file format.\")\n",
    "    df = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d62f3-2d4c-4ec3-a7d0-8f87eae659a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Cell 3: Field Analysis\n",
    "if df is not None:\n",
    "    # Initialize the validator\n",
    "    validator = EnhancedSalesforceValidator()\n",
    "    \n",
    "    # Analyze each field individually\n",
    "    analysis_results = {}\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            analysis_results[column] = validator.analyze_field(column, df[column])\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing column {column}: {str(e)}\")\n",
    "    \n",
    "    # Create report dataframe\n",
    "    report_data = []\n",
    "    for field_name, analysis in analysis_results.items():\n",
    "        report_data.append({\n",
    "            \"Field Name\": field_name,\n",
    "            \"Suggested Type\": analysis.suggested_type,\n",
    "            \"Confidence\": f\"{analysis.confidence:.2%}\",\n",
    "            \"Unique Ratio\": f\"{analysis.unique_ratio:.2%}\",\n",
    "            \"Null Ratio\": f\"{analysis.null_ratio:.2%}\",\n",
    "            \"Sample Values\": \", \".join(str(x) for x in analysis.sample_values[:3]),\n",
    "            \"Validation Pattern\": analysis.validation_pattern\n",
    "        })\n",
    "    \n",
    "    report_df = pd.DataFrame(report_data)\n",
    "    print(\"\\nField Analysis Report:\")\n",
    "    print(report_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab61a4-9be7-42d6-bf3d-c8b838a9e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Cell 4: Visualization of Results\n",
    "def plot_confidence_scores(report_df):\n",
    "    \"\"\"Plot confidence scores for type predictions\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    confidence_values = report_df['Confidence'].str.rstrip('%').astype(float)\n",
    "    \n",
    "    sns.barplot(x=confidence_values, y=report_df['Field Name'])\n",
    "    plt.title('Confidence Scores for Data Type Predictions')\n",
    "    plt.xlabel('Confidence (%)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_type_distribution(report_df):\n",
    "    \"\"\"Plot distribution of suggested types\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    type_counts = report_df['Suggested Type'].value_counts()\n",
    "    type_counts.plot(kind='bar')\n",
    "    plt.title('Distribution of Suggested Data Types')\n",
    "    plt.xlabel('Data Type')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if 'report_df' in locals():\n",
    "    # Generate visualizations\n",
    "    plot_confidence_scores(report_df)\n",
    "    plot_type_distribution(report_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33af24e-3a09-4eee-a0be-20f8167348c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Cell 5: Pattern Matching Analysis\n",
    "def analyze_pattern_matches(df, analysis_results):\n",
    "    \"\"\"Analyze how well each field matches its suggested pattern\"\"\"\n",
    "    pattern_analysis = {}\n",
    "    \n",
    "    for field, analysis in analysis_results.items():\n",
    "        if analysis.validation_pattern and field in df.columns:\n",
    "            # Get non-null values\n",
    "            valid_data = df[field].dropna().astype(str)\n",
    "            if len(valid_data) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Check pattern matches\n",
    "            matches = valid_data.str.match(analysis.validation_pattern, na=False)\n",
    "            match_ratio = matches.mean() if len(matches) > 0 else 0\n",
    "            \n",
    "            # Store results\n",
    "            pattern_analysis[field] = {\n",
    "                'suggested_type': analysis.suggested_type,\n",
    "                'match_ratio': match_ratio,\n",
    "                'total_values': len(valid_data),\n",
    "                'matching_values': int(matches.sum()),\n",
    "                'non_matching_examples': valid_data[~matches].head(3).tolist()\n",
    "            }\n",
    "    \n",
    "    return pd.DataFrame.from_dict(pattern_analysis, orient='index')\n",
    "\n",
    "if df is not None and 'analysis_results' in locals():\n",
    "    pattern_analysis_df = analyze_pattern_matches(df, analysis_results)\n",
    "    print(\"\\nPattern Matching Analysis:\")\n",
    "    print(pattern_analysis_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acf9ae8d-e8e1-4694-abef-b1eb5fc8bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Cell 6: Export Results\n",
    "def export_results(report_df, pattern_analysis_df, output_dir=\"analysis_output\"):\n",
    "    \"\"\"Export analysis results to CSV files\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Export main report\n",
    "    report_df.to_csv(os.path.join(output_dir, \"field_type_analysis.csv\"), index=False)\n",
    "    \n",
    "    # Export pattern analysis\n",
    "    pattern_analysis_df.to_csv(os.path.join(output_dir, \"pattern_matching_analysis.csv\"))\n",
    "    \n",
    "    print(f\"\\nResults exported to {output_dir}/\")\n",
    "\n",
    "if all(var in locals() for var in ['report_df', 'pattern_analysis_df']):\n",
    "    export_results(report_df, pattern_analysis_df)\n",
    "\n",
    "#%% Cell 7: Interactive Pattern Testing\n",
    "def test_pattern(df, field_name, pattern):\n",
    "    \"\"\"Test a custom pattern against a specific field\"\"\"\n",
    "    if field_name not in df.columns:\n",
    "        return \"Field not found in dataset\"\n",
    "    \n",
    "    valid_data = df[field_name].dropna().astype(str)\n",
    "    matches = valid_data.str.match(pattern, na=False)\n",
    "    \n",
    "    return {\n",
    "        'match_ratio': matches.mean() if len(matches) > 0 else 0,\n",
    "        'total_values': len(valid_data),\n",
    "        'matching_values': int(matches.sum()),\n",
    "        'non_matching_examples': valid_data[~matches].head(3).tolist()\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "# if df is not None:\n",
    "#     test_results = test_pattern(df, 'email_field', r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$')\n",
    "#     print(test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
